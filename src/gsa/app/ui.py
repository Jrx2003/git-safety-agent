from __future__ import annotations

import os
import re
import uuid
from typing import Any, Dict, List, Optional

import streamlit as st

from gsa.agent.clarifier import clarify_questions
from gsa.agent.orchestrator import Orchestrator
from gsa.llm.llm_client import load_config


st.set_page_config(page_title="Git Safety Agent", layout="wide")


def _default_workspace() -> str:
    return os.environ.get("GSA_WORKSPACE", os.getcwd())


@st.cache_resource

def get_orchestrator(workspace: str) -> Orchestrator:
    return Orchestrator(workspace)


@st.cache_data

def get_tree_items(workspace: str, max_depth: int) -> List[str]:
    orch = get_orchestrator(workspace)
    data = orch.mcp.call_tool("file_list", {"dir": ".", "max_depth": max_depth})
    return data.get("items", [])


@st.cache_data

def get_git_graph(workspace: str, n: int, author: str, branch: str, path: str) -> str:
    orch = get_orchestrator(workspace)
    data = orch.mcp.call_tool(
        "git_log_graph",
        {
            "n": n,
            "author": author or None,
            "branch": branch or None,
            "path": path or None,
        },
    )
    return data.get("stdout", "")


def build_tree(items: List[str]) -> Dict[str, Any]:
    tree: Dict[str, Any] = {"__files__": []}
    for item in items:
        path = item.replace("./", "").strip()
        if not path or path in {".", "./"}:
            continue
        if path.endswith("/"):
            parts = path.strip("/").split("/")
            node = tree
            for p in parts:
                node = node.setdefault(p, {"__files__": []})
        else:
            parts = path.split("/")
            *dirs, fname = parts
            node = tree
            for d in dirs:
                node = node.setdefault(d, {"__files__": []})
            node.setdefault("__files__", []).append(fname)
    return tree


def render_tree(node: Dict[str, Any], base: str = "") -> None:
    dirs = sorted([k for k in node.keys() if k != "__files__"])
    files = sorted(node.get("__files__", []))
    for d in dirs:
        with st.expander(f"ğŸ“ {d}", expanded=False):
            render_tree(node[d], os.path.join(base, d) if base else d)
    for f in files:
        full_path = os.path.join(base, f) if base else f
        if st.button(f"ğŸ“„ {f}", key=f"file_{full_path}"):
            st.session_state["preview_file"] = full_path


def append_message(role: str, content: str) -> None:
    st.session_state.setdefault("messages", []).append({"role": role, "content": content})


def render_messages() -> None:
    for msg in st.session_state.get("messages", []):
        with st.chat_message(msg["role"]):
            st.write(msg["content"])


def _friendly_error(errors: List[str], has_plan: bool) -> Optional[str]:
    if not errors:
        return None
    if has_plan:
        errors = [e for e in errors if "è§„åˆ’ç»“æœè§£æå¤±è´¥" not in e]
        if not errors:
            return None
    text = "\n".join(errors)
    if "BIGMODEL_API_KEY" in text:
        return "æœªæ£€æµ‹åˆ° API Keyã€‚è¯·é…ç½® BIGMODEL_API_KEYï¼ˆç¯å¢ƒå˜é‡æˆ– config.yamlï¼‰ã€‚"
    if "timed out" in text or "è¶…æ—¶" in text:
        return "LLM è°ƒç”¨è¶…æ—¶ï¼Œå·²è‡ªåŠ¨é™çº§ä¸ºè§„åˆ™è§„åˆ’ã€‚è¯·æ£€æŸ¥ç½‘ç»œä¸ API Keyã€‚"
    if "LLM è°ƒç”¨å¤±è´¥" in text:
        return "LLM è°ƒç”¨å¤±è´¥ï¼Œé”™è¯¯ä¿¡æ¯å¦‚ä¸‹ï¼š\n" + text
    return "è§„åˆ’æ ¡éªŒå‡ºç°é—®é¢˜ï¼š\n" + text


def _plan_summary_text(plan) -> str:
    lines = [f"æ„å›¾ï¼š{plan.intent}"]
    if not plan.steps:
        lines.append("æœªç”Ÿæˆæ­¥éª¤ã€‚")
        return "\n".join(lines)
    lines.append("æˆ‘å°†å°è¯•æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š")
    for idx, step in enumerate(plan.steps, 1):
        lines.append(
            f"{idx}. {step.tool}ï½œé£é™©ï¼š{step.safety_level}ï½œåŸå› ï¼š{step.safety_reason}"
        )
    if plan.needs_confirmation:
        lines.append("è¯¥è®¡åˆ’åŒ…å«å†™æ“ä½œï¼Œéœ€è¦ YES ç¡®è®¤ã€‚")
    return "\n".join(lines)


def _render_long_text(title: str, text: str, as_code: bool = False) -> None:
    if len(text) > 800:
        with st.expander(title, expanded=False):
            if as_code:
                st.code(text, language="text")
            else:
                st.write(text)
    else:
        if as_code:
            st.code(text, language="text")
        else:
            st.write(text)


def _is_code_like(text: str, query: str) -> bool:
    if "```" in text:
        return True
    if re.search(r"\b(ä»£ç |code|å‡½æ•°|ç±»)\b", query):
        return True
    if re.search(r"\b(def |class |import |from |if __name__|@)\b", text):
        return True
    return False


def _render_qa_answer(answer: str, sources: List[str], query: str) -> None:
    if not answer:
        st.write("æœªè¿”å›ç­”æ¡ˆã€‚")
        return
    if "```" in answer:
        if len(answer) > 800:
            with st.expander("å±•å¼€å›ç­”", expanded=False):
                st.markdown(answer)
        else:
            st.markdown(answer)
    else:
        _render_long_text("å±•å¼€å›ç­”", answer, as_code=_is_code_like(answer, query))
    if sources:
        with st.expander("å‚è€ƒæ–‡ä»¶", expanded=False):
            st.write("\n".join([f"- {s}" for s in sources]))


def _handle_chat_request(orch: Orchestrator, user_input: str, chat_mode: str) -> None:
    pending_questions = st.session_state.get("pending_questions")
    base_input = st.session_state.get("pending_base_input", "")

    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨è§„åˆ’..."):
            if chat_mode == "ç´¢å¼•é—®ç­”":
                res = orch.mcp.call_tool("index_qa", {"query": user_input, "top_k": 6})
                if not res.get("ok", True):
                    if "ç´¢å¼•ä¸å­˜åœ¨" in str(res.get("error")):
                        msg = (
                            "ç´¢å¼•å°šæœªæ„å»ºã€‚ç´¢å¼•ä¼šæŠŠæœ¬åœ°æ–‡ä»¶åˆ‡ç‰‡å¹¶å»ºç«‹å‘é‡æ£€ç´¢ï¼Œ"
                            "ä½¿æ¨¡å‹èƒ½åŸºäºæºç å‡†ç¡®å›ç­”é—®é¢˜ã€‚"
                        )
                        st.session_state["need_index"] = True
                        st.session_state["need_index_msg"] = msg
                    else:
                        msg = res.get("error", "ç´¢å¼•é—®ç­”å¤±è´¥")
                    st.write(msg)
                    append_message("assistant", msg)
                else:
                    answer = res.get("answer", "")
                    sources = res.get("sources", [])
                    snippets = res.get("snippets", [])
                    _render_qa_answer(answer, sources, user_input)
                    if snippets:
                        with st.expander("ç›¸å…³ç‰‡æ®µ", expanded=False):
                            for snip in snippets:
                                src = snip.get("source") or "æœªçŸ¥æ¥æº"
                                text = snip.get("content", "")
                                st.markdown(f"**{src}**")
                                if _is_code_like(text, user_input):
                                    st.code(text, language="text")
                                else:
                                    st.write(text)
                    msg = answer
                    if sources:
                        msg += "\n\nå‚è€ƒæ–‡ä»¶ï¼š\n" + "\n".join([f"- {s}" for s in sources])
                    append_message("assistant", msg)
                return

            if pending_questions:
                combined = base_input + "\nè¡¥å……ä¿¡æ¯: " + user_input
                st.session_state["pending_questions"] = []
            else:
                combined = user_input
                st.session_state["pending_base_input"] = user_input

            orch.use_llm = True
            result = orch.plan(combined)
            st.session_state["last_plan_result"] = result

            msg = _friendly_error(result.errors, has_plan=bool(result.plan))
            if msg:
                st.write(msg)
                append_message("assistant", msg)

            if result.plan:
                if result.plan.questions:
                    qs = clarify_questions(result.plan.questions)
                    msg2 = "æˆ‘éœ€è¦è¿›ä¸€æ­¥æ¾„æ¸…ï¼š\n" + qs
                    st.write(msg2)
                    append_message("assistant", msg2)
                    st.session_state["pending_questions"] = result.plan.questions
                else:
                    msg2 = _plan_summary_text(result.plan)
                    st.write(msg2)
                    append_message("assistant", msg2)


def _handle_quick_action(orch: Orchestrator, action: str) -> None:
    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨è§„åˆ’..."):
            if action == "repo_summarize":
                res = orch.mcp.call_tool("repo_summarize", {})
                if not res.get("ok", True) and "ç´¢å¼•ä¸å­˜åœ¨" in str(res.get("error")):
                    msg = (
                        "ç´¢å¼•å°šæœªæ„å»ºã€‚ç´¢å¼•ä¼šæŠŠæœ¬åœ°æ–‡ä»¶åˆ‡ç‰‡å¹¶å»ºç«‹å‘é‡æ£€ç´¢ï¼Œ"
                        "ä½¿æ¨¡å‹èƒ½åŸºäºæºç å‡†ç¡®å›ç­”é—®é¢˜ã€‚"
                    )
                    st.session_state["need_index"] = True
                    st.session_state["need_index_msg"] = msg
                else:
                    msg = res.get("summary", "") if res.get("ok", True) else res.get("error", "æ¦‚è§ˆå¤±è´¥")
                st.write(msg)
                append_message("assistant", msg)
                return
            if action == "organize_suggestions":
                res = orch.mcp.call_tool("organize_suggestions", {})
                if not res.get("ok", True) and "ç´¢å¼•ä¸å­˜åœ¨" in str(res.get("error")):
                    msg = (
                        "ç´¢å¼•å°šæœªæ„å»ºã€‚ç´¢å¼•ä¼šæŠŠæœ¬åœ°æ–‡ä»¶åˆ‡ç‰‡å¹¶å»ºç«‹å‘é‡æ£€ç´¢ï¼Œ"
                        "ä½¿æ¨¡å‹èƒ½åŸºäºæºç å‡†ç¡®å›ç­”é—®é¢˜ã€‚"
                    )
                    st.session_state["need_index"] = True
                    st.session_state["need_index_msg"] = msg
                else:
                    if not res.get("ok", True):
                        msg = res.get("error", "æ•´ç†å»ºè®®å¤±è´¥")
                    else:
                        msg = res.get("suggestions", "")
                        st.session_state["last_suggestions"] = msg
                st.write(msg)
                append_message("assistant", msg)
                return
            msg = "æœªçŸ¥æ“ä½œ"
            st.write(msg)
            append_message("assistant", msg)


def main():
    st.title("Git Safety Agent")
    st.markdown(
        """
        <style>
        section[data-testid="stSidebar"] { width: 360px !important; }
        </style>
        """,
        unsafe_allow_html=True,
    )
    if "workspace" not in st.session_state:
        st.session_state["workspace"] = _default_workspace()
    workspace = st.session_state["workspace"]

    orch = get_orchestrator(workspace)
    pending_request = st.session_state.get("pending_request")
    pending_request_handled = st.session_state.get("pending_request_handled", False)
    pending_quick = st.session_state.get("pending_quick_action")
    pending_quick_handled = st.session_state.get("pending_quick_action_handled", False)
    busy = bool(
        st.session_state.get("processing", False)
        or (pending_request and not pending_request_handled)
        or (pending_quick and not pending_quick_handled)
    )

    with st.sidebar:
        with st.expander("æ¨¡å‹é…ç½®", expanded=True):
            cfg = load_config(workspace)
            base_options = {
                "å›½å†…ï¼ˆopen.bigmodel.cnï¼‰": "https://open.bigmodel.cn/api/paas/v4/",
                "æµ·å¤–ï¼ˆapi.z.aiï¼‰": "https://api.z.ai/api/paas/v4/",
            }
            current_url = st.session_state.get("base_url_override") or cfg.base_url
            base_index = 0 if "open.bigmodel.cn" in current_url else 1
            col_a, col_b = st.columns(2)
            with col_a:
                base_label = st.selectbox("æ¥å£åœ°å€", list(base_options.keys()), index=base_index)
            with col_b:
                model = st.selectbox(
                    "æ¨¡å‹é€‰æ‹©",
                    ["glm-4.7", "glm-4.7-flash"],
                    index=0 if cfg.model == "glm-4.7" else 1,
                )
            selected_url = base_options[base_label]
            st.session_state["base_url_override"] = selected_url
            os.environ["BIGMODEL_BASE_URL"] = selected_url
            orch.planner.set_base_url(selected_url)
            orch.planner.set_model(model)

        with st.expander("å¯¹è¯", expanded=True):
            chat_mode = st.radio(
                "æ¨¡å¼",
                ["è®¡åˆ’æ‰§è¡Œ", "ç´¢å¼•é—®ç­”"],
                horizontal=True,
            )
            st.session_state["chat_mode"] = chat_mode
            col_q1, col_q2 = st.columns(2)
            with col_q1:
                if st.button("ä¸€é”®ä»“åº“æ¦‚è§ˆ"):
                    append_message("user", "ä¸€é”®ä»“åº“æ¦‚è§ˆ")
                    st.session_state["pending_quick_action"] = {"id": uuid.uuid4().hex, "action": "repo_summarize"}
                    st.session_state["pending_quick_action_handled"] = False
                    st.rerun()
            with col_q2:
                if st.button("ä¸€é”®æ•´ç†å»ºè®®"):
                    append_message("user", "ä¸€é”®æ•´ç†å»ºè®®")
                    st.session_state["pending_quick_action"] = {"id": uuid.uuid4().hex, "action": "organize_suggestions"}
                    st.session_state["pending_quick_action_handled"] = False
                    st.rerun()

            with st.form("sidebar_chat", clear_on_submit=True, border=False):
                user_input = st.text_input("è¾“å…¥è‡ªç„¶è¯­è¨€ä»»åŠ¡", placeholder="è¾“å…¥è‡ªç„¶è¯­è¨€ä»»åŠ¡...", disabled=busy, label_visibility="collapsed")
                send = st.form_submit_button("å‘é€", disabled=busy, use_container_width=True)
            if send and user_input.strip():
                prefix = "è®¡åˆ’æ‰§è¡Œ" if chat_mode == "è®¡åˆ’æ‰§è¡Œ" else "ç´¢å¼•é—®ç­”"
                append_message("user", f"{prefix}ï¼š{user_input}")
                st.session_state["pending_request"] = {
                    "id": uuid.uuid4().hex,
                    "input": user_input,
                    "mode": chat_mode,
                }
                st.session_state["pending_request_handled"] = False
                st.rerun()

        with st.expander("å·¥ä½œåŒº", expanded=False):
            st.caption(f"å½“å‰ï¼š{workspace}")
            ws_input = st.text_input("åˆ‡æ¢å·¥ä½œåŒº", value=workspace)
            if st.button("åº”ç”¨å·¥ä½œåŒº"):
                if not os.path.isdir(ws_input):
                    st.error("è·¯å¾„ä¸å­˜åœ¨æˆ–ä¸å¯è®¿é—®")
                else:
                    st.session_state["workspace"] = ws_input
                    st.cache_data.clear()
                    st.rerun()

        with st.expander("ç›®å½•ç»“æ„", expanded=False):
            query = st.text_input("å¿«é€Ÿæœç´¢è·¯å¾„")
            preview_enabled = st.checkbox("å¯ç”¨æ–‡ä»¶é¢„è§ˆ", value=True)
            st.session_state["preview_enabled"] = preview_enabled
            if st.button("åˆ·æ–°ç›®å½•"):
                st.cache_data.clear()
            items = get_tree_items(workspace, 3)
            if query:
                items = [i for i in items if query in i]
            tree = build_tree(items)
            render_tree(tree)

        with st.expander("Git å†å²", expanded=False):
            n = st.slider("æäº¤æ•°é‡", 5, 80, 30)
            branch = st.text_input("åˆ†æ”¯è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰", value="")
            author = st.text_input("ä½œè€…è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰", value="")
            path = st.text_input("æ–‡ä»¶è·¯å¾„è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰", value="")
            if st.button("åˆ·æ–°å†å²"):
                st.cache_data.clear()
            graph = get_git_graph(workspace, n, author, branch, path)
            st.code(graph, language="text")

    with st.container():
        messages = st.session_state.get("messages", [])
        if messages:
            st.subheader("å¯¹è¯åŒº")
            render_messages()
        else:
            st.markdown(
                """
                <div style="text-align:center;padding:6rem 0 3rem;">
                  <h3>æ¬¢è¿ä½¿ç”¨ Git Safety Agent</h3>
                  <p>è¾“å…¥è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼Œæˆ‘ä¼šå…ˆè§„åˆ’å†æ‰§è¡Œï¼Œç¡®ä¿æ“ä½œå¯æ§å¯å›æº¯ã€‚</p>
                  <p>ä½ å¯ä»¥å°è¯•ï¼š</p>
                  <p>â€¢ åˆå§‹åŒ– Git ä»“åº“â€ƒâ€¢ æŸ¥çœ‹æœ€è¿‘æäº¤å†å²â€ƒâ€¢ ä¸€é”®ä»“åº“æ¦‚è§ˆâ€ƒâ€¢ ä¸€é”®æ•´ç†å»ºè®®</p>
                  <p>åˆ‡æ¢åˆ°â€œç´¢å¼•é—®ç­”â€æ¨¡å¼ï¼Œè¿˜å¯ä»¥å°±æºç æé—®ã€‚</p>
                </div>
                """,
                unsafe_allow_html=True,
            )

        if pending_request and not pending_request_handled:
            req = st.session_state.get("pending_request", {})
            st.session_state["processing"] = True
            try:
                _handle_chat_request(orch, req.get("input", ""), req.get("mode", "è®¡åˆ’æ‰§è¡Œ"))
            finally:
                st.session_state["processing"] = False
                st.session_state["pending_request_handled"] = True
                st.session_state["pending_request"] = None
                st.session_state["post_handle_rerun"] = True

        if pending_quick and not pending_quick_handled:
            qa = st.session_state.get("pending_quick_action", {})
            st.session_state["processing"] = True
            try:
                _handle_quick_action(orch, qa.get("action", ""))
            finally:
                st.session_state["processing"] = False
                st.session_state["pending_quick_action_handled"] = True
                st.session_state["pending_quick_action"] = None
                st.session_state["post_handle_rerun"] = True

        suggestions = st.session_state.get("last_suggestions")
        if suggestions:
            if st.button("æ ¹æ®æœ€è¿‘æ•´ç†å»ºè®®ç”Ÿæˆæ‰§è¡Œè®¡åˆ’"):
                with st.chat_message("user"):
                    st.write("è¯·æ ¹æ®æœ€è¿‘æ•´ç†å»ºè®®ç”Ÿæˆå¯æ‰§è¡Œè®¡åˆ’")
                append_message("user", "è¯·æ ¹æ®æœ€è¿‘æ•´ç†å»ºè®®ç”Ÿæˆå¯æ‰§è¡Œè®¡åˆ’")
                prompt = "ä»¥ä¸‹æ˜¯æ•´ç†å»ºè®®ï¼Œè¯·ç”Ÿæˆå¯æ‰§è¡Œçš„è®¡åˆ’æ­¥éª¤ï¼š\n" + suggestions
                with st.chat_message("assistant"):
                    with st.spinner("æ­£åœ¨è§„åˆ’..."):
                        orch.use_llm = True
                        result = orch.plan(prompt)
                        st.session_state["last_plan_result"] = result
                        msg = _friendly_error(result.errors, has_plan=bool(result.plan))
                        if msg:
                            st.write(msg)
                            append_message("assistant", msg)
                        if result.plan:
                            if result.plan.questions:
                                qs = clarify_questions(result.plan.questions)
                                msg2 = "æˆ‘éœ€è¦è¿›ä¸€æ­¥æ¾„æ¸…ï¼š\n" + qs
                                st.write(msg2)
                                append_message("assistant", msg2)
                                st.session_state["pending_questions"] = result.plan.questions
                            else:
                                msg2 = _plan_summary_text(result.plan)
                                st.write(msg2)
                                append_message("assistant", msg2)

        plan_result = st.session_state.get("last_plan_result")
        selected_plan = None
        if plan_result and plan_result.plan:
            with st.expander("æŸ¥çœ‹è®¡åˆ’ JSON", expanded=False):
                st.json(plan_result.plan.model_dump())

            st.subheader("æ‰§è¡Œæ§åˆ¶")
            st.caption("é€‰æ‹©è¦æ‰§è¡Œçš„æ­¥éª¤ï¼ˆå¯å¤šé€‰ï¼‰")
            selected_indices: List[int] = []
            for i, step in enumerate(plan_result.plan.steps):
                key = f"step_select_{plan_result.trace_id}_{i}"
                label = f"{i+1}. {step.tool}ï½œé£é™©ï¼š{step.safety_level}ï½œåŸå› ï¼š{step.safety_reason}"
                checked = st.checkbox(label, value=True, key=key)
                if checked:
                    selected_indices.append(i)

            if selected_indices:
                selected_steps = [s for idx, s in enumerate(plan_result.plan.steps) if idx in selected_indices]
                needs_confirm = any(s.safety_level in {"medium", "high"} for s in selected_steps)
                selected_plan = plan_result.plan.model_copy(
                    update={"steps": selected_steps, "needs_confirmation": needs_confirm}
                )
            else:
                st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€æ¡æ­¥éª¤å†æ‰§è¡Œã€‚")

            confirmed = st.checkbox("æˆ‘å·²é˜…è¯»é£é™©å¹¶ç¡®è®¤æ‰§è¡Œï¼ˆYESï¼‰", value=False)
            col_run, col_dry = st.columns(2)
            with col_run:
                if st.button("æ‰§è¡Œè®¡åˆ’", disabled=not selected_plan):
                    with st.spinner("æ‰§è¡Œä¸­..."):
                        exec_res = orch.execute(selected_plan, plan_result.trace_id, confirmed=confirmed)
                        st.session_state["exec_result"] = exec_res
            with col_dry:
                if st.button("ä»…è¯•è¿è¡Œ", disabled=not selected_plan):
                    with st.spinner("è¯•è¿è¡Œä¸­..."):
                        exec_res = orch.execute(selected_plan, plan_result.trace_id, confirmed=False)
                        st.session_state["exec_result"] = exec_res

    exec_result = st.session_state.get("exec_result")
    if exec_result:
        st.subheader("æ‰§è¡Œç»“æœ")
        st.info(exec_result.get("summary", ""))
        st.caption("æ‰§è¡Œæ˜ç»†")
        for item in exec_result.get("results", []):
            tool = item.get("tool", "")
            ok = item.get("ok", False)
            st.write(f"- {tool}ï¼š{'æˆåŠŸ' if ok else 'å¤±è´¥'}")
        with st.expander("é”™è¯¯æ‘˜è¦", expanded=False):
            has_error = False
            for item in exec_result.get("results", []):
                tool = item.get("tool", "")
                if not item.get("ok"):
                    st.markdown(f"**{tool}**")
                    st.write(item.get("error", "æœªçŸ¥é”™è¯¯"))
                    has_error = True
                    continue
                result = item.get("result", {})
                stderr = result.get("stderr")
                if stderr:
                    st.markdown(f"**{tool}**")
                    st.code(stderr, language="text")
                    has_error = True
            if not has_error:
                st.write("æ— é”™è¯¯ã€‚")
        st.info(f"trace_id: {exec_result.get('trace_id')}")
        log_path = os.path.join(orch.workspace, ".gsa", "logs")
        st.info(f"æ—¥å¿—ç›®å½•ï¼š{log_path}")
        try:
            files = sorted(os.listdir(log_path))
            if files:
                latest = os.path.join(log_path, files[-1])
                with open(latest, "r", encoding="utf-8") as f:
                    lines = f.read().splitlines()[-50:]
                st.code("\n".join(lines), language="json")
        except Exception:
            pass

        if st.session_state.get("need_index"):
            st.subheader("ç´¢å¼•æç¤º")
            st.info(st.session_state.get("need_index_msg", "éœ€è¦å…ˆæ„å»ºç´¢å¼•ã€‚"))
            if st.button("æ„å»ºç´¢å¼•"):
                with st.spinner("æ­£åœ¨æ„å»ºç´¢å¼•..."):
                    res = orch.mcp.call_tool(
                        "index_build",
                        {"include_globs": ["**/*"], "exclude_globs": [], "dry_run": False},
                    )
                if res.get("ok", True):
                    msg = (
                        f"ç´¢å¼•å·²æ„å»ºï¼šæ–‡æ¡£ {res.get('docs')}ï¼Œ"
                        f"åˆ‡ç‰‡ {res.get('chunks')}ã€‚è¯·é‡æ–°æé—®ã€‚"
                    )
                    st.session_state["need_index"] = False
                    st.session_state["need_index_msg"] = ""
                else:
                    msg = res.get("error", "ç´¢å¼•æ„å»ºå¤±è´¥")
                st.write(msg)
                append_message("assistant", msg)

        if st.session_state.get("post_handle_rerun"):
            st.session_state["post_handle_rerun"] = False
            st.rerun()

    preview_enabled = st.session_state.get("preview_enabled", True)
    preview_path = st.session_state.get("preview_file", "")
    if preview_enabled and preview_path:
        st.subheader("æ–‡ä»¶é¢„è§ˆ")
        st.caption(f"é¢„è§ˆï¼š{preview_path}")
        content = orch.mcp.call_tool("file_read", {"path": preview_path})
        if not content.get("ok", True):
            st.error(content.get("error", "è¯»å–å¤±è´¥"))
        else:
            text = content.get("content", "")
            if not text:
                st.info("æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•æ˜¾ç¤ºï¼ˆå¯èƒ½ä¸ºäºŒè¿›åˆ¶æˆ–å†…å®¹è¿‡å¤§ï¼‰ã€‚")
            else:
                st.text_area("æ–‡ä»¶å†…å®¹é¢„è§ˆ", text, height=260, disabled=True, label_visibility="collapsed")


if __name__ == "__main__":
    main()
